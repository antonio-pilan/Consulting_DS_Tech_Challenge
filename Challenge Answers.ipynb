{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1) What steps would you take to solve this problem? Please describe as completely and clearly as possible all the steps that you see as essential for solving the problem. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to understand the Business Problem and align all informations before going technicall and deal with Data. Understanding what each feature means for further feature engineerig and understating possible correlations. In our case, we're dealing with a specific truck maintenance cost, our data is encoded and not given further instructions, so we'll consider that each feature is one path that company operates and each row is a truck maintenance cost in each path. 0 Values means that a truck doesnt need maintenance at that specific path. NaN values means that the data was not given.\n",
    "\n",
    "Then, once we understand what are we dealing with, we start to understand our data quality and overall schema. We make our EDA and process missing values, deal with quality and optimize data. In our case, we'll have two options: filling missing data with 0 or dropping NaN values. The reasons is debated on Jupyter's Notebook that contains my EDA, but in we can think that is most accurate to assume that a value that is missing is a track that the specific truck didnt made, so we fill it with 0. But if we have a lot of missing values we would be making a lot of assumptions and would affect our model. So we should decide as we do our EDA.\n",
    "\n",
    "Then we'll go to Feature Engineering and enhancing our data. We can normalize and standardize our data for our numeric features doesnt have any magnitude bias if we're working with classifiers.\n",
    "We can also encode categorical features but, on our case, that wont be necessary. We also separate our data on training group and test group, then we'll start to create our model.\n",
    "\n",
    "Once we have the features stablished we can structure our model, on our case we'll use classifiers such as XGBoost, RandomForest or Extra Trees.\n",
    "\n",
    "With our model in hands, we can evaluate ML performance metrics and algorithms. We'll use Cost as our main KPI.\n",
    "\n",
    "Then, if we keep the work with the hiring business, we can keep improving and re evaluating our data and model to optmize results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2) Which technical data science metric would you use to solve this challenge? Ex: absolute error, rmse, etc. </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On jupyter notebook we discover that our data isn't balanced so absolute metrics shouldn't be good as Accuracy, but there's many good DS performance metrics we could use like Precision and Recall. We can also analyse Confusion Matrix.\n",
    "\n",
    "This are good metrics for the model I first chose to use initially, if we used numerical models such as regressions we could use some more performance indicators as well like $RË†{2}$ or $RSME$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3) Which business metric  would you use to solve the challenge?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metric we're trying to optimize is maintenance cost of air system. so we should look at it as main KPI. But a more profound study can be made with the transport company to analyse so secondary indicators that may be correlated to the main one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>4) How do technical metrics relate to the business metrics?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used confusion matrix to analyse false negatives (really expensive) and false positives (relativelly cheap) to optimize overall cost by prioritizing maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>5) What types of analyzes would you like to perform on the customer database?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many important things i would like to know about database to optimize, mainly data cleaning. First one is what exactly each column and row means and how it is inputed in the system. Analyzing outliers and how to treat them. \n",
    "\n",
    "One of the things can be done is to understand true positives values, on our model we adopted false positive as $25 maintenance instad of $10, but a more profound study can make we consider things like \"How much of true positive are $25 maintenance and how many are other maintenances, how does that relate\". With this we can be more accurate on the final maintenance cost.\n",
    "\n",
    "A lot of things can be made and can be learnt as we go developing the solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>6) What techniques would you use to reduce the dimensionality of the problem? </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check statistically some techniques to enhance the reduction, like Missing Value Ratio or High Correlation Filter to only use relevant features on our classifier.\n",
    "\n",
    "(i know we chose to input 0 in NaN instead of dropping them, but Missing Value Ration can(and should) be debated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>7) What techniques would you use to select variables for your predictive model? </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First one i'd do in this specific problem is to check correlation between variables and target. Good correlation may boost significantly our model. We can test stepwise selectio or correlation matrix to check correlation between features and target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>8) What predictive models would you use or test for this problem? Please indicate at least 3.</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will teste mainly XGBoost, Extra Trees Classifier and Decision Trees for this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>9) How would you rate which of the trained models is the best?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the lowest cost among the models. We can also evaluate confusion matrix to understand where the model is making mistakes and change it or optmize it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>10) How would you explain the result of your model? Is it possible to know which variables are most important?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XBoost is a smart model that work well for our many featured system because it learns from past mistakes. We can see feature importance on its module and its more accutate than Random Forest because of its inteligence and not randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>11) How would you assess the financial impact of the proposed model?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is deployed, i would analyze weekly or monthly how it affected air system maintenance cost. If it have tendency to go down and technical metrics appoints good performance of our models, we should report it as a good model impact in decisionmaking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>12) What techniques would you use to perform the hyperparameter optimization of the chosen model?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used gridsearch to compare different hyperparameters in different models. The best optmized model was chosen as model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>13) What risks or precautions would you present to the customer before putting this model into production?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are statistical and we try as much as possible to run from bias when building models. But as stated, having a lot o NaN values and lost of information may impact real-life experience because this data is mainly not being evaluated by our model, so everything should work together to improve the product. We also need to be careful about overfitting, good metrics dont always mean a good model, so it need to be constantly studied and evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>14) If your predictive model is approved, how would you put it into production?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploying a model can be relatively big and personalized. We can make a system using Streamlit or even Django integrated on web for the client to access and monitor or even implement automated decisions on their systems. As an example we can send automated emails when our model detects that a truck needs air system maintenance. \n",
    "\n",
    "Everything should be very well aligned with the company, their workflow and expectations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>15) If the model is in production, how would you monitor it?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are Data Scientists! we can make dashboards to monitor real-time decision making for our model. Follow the metrics the team decided and the impacts that it leads to our main KPI. Overall if our system seems to work fine and actions are being done with the deploy strategy, we should see costs drop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>16) If the model is in production, how would you know when to retrain it?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if our accuracy comes down or other indicators like accuracy,precision or recall. Input data can be monitored too, if incoming data changes a lot over time we should retrain the model for the new characteristics. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
